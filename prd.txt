알겠습니다. `langchain-google-genai` 관련 내용을 제외하고 수정한 PRD를 다시 작성해 드립니다.

---

## Langchain & Firecrawl 연동 에이전트 개발 PRD (Product Requirements Document)

### 1. 문서 개요
- **문서명:** Langchain Firecrawl 연동 에이전트 개발
- **작성자:** Gemini
- **작성일:** 2025년 6월 30일
- **버전:** 1.1

### 2. 프로젝트 개요 (Overview)
본 프로젝트는 최신 웹 스크래핑/크롤링 솔루션인 **Firecrawl**을 **Langchain** 생태계에 통합하는 것을 목표로 합니다. Firecrawl의 강력한 웹 정보 추출 기능을 Langchain의 Tool로 개발하고, 이를 활용하여 자연어 기반의 사용자 요청을 자율적으로 처리하는 지능형 에이전트를 구현합니다. 최종적으로는 실제 웹사이트(무신사) 데이터를 활용한 RAG(Retrieval-Augmented Generation) 패턴의 구체적인 활용 사례를 제시하여 프로젝트의 실용성을 검증합니다.

### 3. 목표 (Goals)

1.  **핵심 기능 검증:**
    * 지정된 단일 URL에 대한 Firecrawl의 `scrape` 모드가 정상적으로 동작하여, 광고 및 불필요한 요소를 제거한 핵심 콘텐츠(Markdown)를 추출하는지 확인합니다.
    * 지정된 시작 URL로부터 하위 페이지들을 순회하며 데이터를 수집하는 `crawl` 모드의 정상 동작을 확인합니다.

2.  **Langchain Tool 개발:**
    * Firecrawl의 `scrape` 및 `crawl` 기능을 각각의 Langchain `Tool`로 래핑(wrapping)합니다.
    * 개발된 Tool은 Langchain 에이전트가 명확히 인지하고 사용할 수 있도록 명확한 `name`, `description`, `args_schema`를 가져야 하며, Langchain 생태계 내에서 재사용 가능하도록 모듈화합니다.

3.  **지능형 에이전트 구현:**
    * 생성된 Firecrawl Tool을 장착한 Langchain 에이전트(Agent)를 구현합니다.
    * 에이전트는 "X 웹사이트의 정보를 요약해줘" 또는 "Y 웹사이트에서 Z에 대한 정보를 찾아줘"와 같은 사용자의 자연어 요청을 이해하고, 상황에 맞는 Tool(scrape 또는 crawl)을 자율적으로 선택 및 실행하여 결과를 도출해야 합니다.

4.  **실용적 활용 사례 제시 (RAG 패턴):**
    * 국내 대표 패션 플랫폼 '무신사' 웹페이지를 대상으로 간단한 RAG 패턴을 구현합니다.
    * **시나리오:** "무신사에서 요즘 인기 있는 반팔 티셔츠 상품 3가지만 추천해줘"
    * **구현:** Firecrawl로 특정 카테고리 페이지를 크롤링 -> 수집된 데이터를 Vector Store에 저장(Indexing) -> 사용자 질문에 가장 관련성 높은 상품 정보 검색(Retrieval) -> 검색된 정보를 바탕으로 LLM이 최종 답변 생성(Generation)

### 4. 주요 기능 명세 (Key Feature Specifications)

#### 4.1. Firecrawl 핵심 기능 검증
- **입력:**
    - Firecrawl API Key
    - 테스트 대상 URL (e.g., 뉴스 기사, 블로그 포스트, 상품 페이지)
- **프로세스:**
    - **Scrape 모드:** 단일 URL을 입력하여 Firecrawl `scrape` API를 호출하고, 반환된 Markdown 형식의 본문 데이터를 확인합니다.
    - **Crawl 모드:** 특정 도메인의 시작 URL을 입력하여 `crawl` API를 호출하고, 여러 페이지의 데이터가 구조화된 형태(JSON)로 반환되는지 확인합니다.
- **출력:**
    - Scrape: 정제된 Markdown 텍스트
    - Crawl: 각 페이지의 `metadata`와 `markdown`을 포함하는 JSON 객체 리스트
- **검증 환경:** Jupyter Notebook 또는 간단한 Python 스크립트

#### 4.2. Langchain Tool 개발 (`FirecrawlScrapeTool`, `FirecrawlCrawlTool`)

- **`FirecrawlScrapeTool`**
    - **클래스:** `langchain_core.tools.BaseTool` 상속
    - **`name`:** `firecrawl_scrape_url`
    - **`description`:** "하나의 웹 페이지 URL을 입력받아 광고나 방해 요소를 제거한 핵심 콘텐츠를 텍스트(Markdown) 형식으로 반환합니다. 특정 페이지의 내용을 정확히 가져와야 할 때 사용하세요."
    - **`args_schema`:** Pydantic `BaseModel`을 사용하여 입력으로 `url: str`을 명시
    - **로직:** 입력받은 `url`을 Firecrawl `scrape` API에 전달하고, 결과 텍스트를 반환합니다. 오류 발생 시 예외 처리를 포함합니다.

- **`FirecrawlCrawlTool`**
    - **클래스:** `langchain_core.tools.BaseTool` 상속
    - **`name`:** `firecrawl_crawl_website`
    - **`description`:** "시작 URL을 입력받아 해당 웹사이트를 순회(crawling)하며 여러 페이지의 정보를 수집합니다. 웹사이트 전반의 정보나 특정 주제에 대한 여러 페이지의 데이터가 필요할 때 사용하세요. 크롤링 깊이나 최대 페이지 수 같은 파라미터를 함께 지정할 수 있습니다."
    - **`args_schema`:** Pydantic `BaseModel`을 사용하여 `url: str`, `crawlerOptions: dict` (선택 사항) 등을 명시
    - **로직:** 입력받은 `url`과 옵션을 Firecrawl `crawl` API에 전달하고, 수집된 페이지 데이터 리스트를 JSON 형태의 문자열로 반환합니다.

#### 4.3. Langchain 에이전트 구현
- **에이전트 타입:** ReAct (Reasoning and Acting) 또는 OpenAI Functions Agent
- **구성 요소:**
    - **LLM:** `ChatOpenAI(gpt-4-turbo)` 등 고성능 언어 모델
    - **Tools:** 위에서 개발한 `FirecrawlScrapeTool`, `FirecrawlCrawlTool`
    - **Prompt:** 에이전트의 역할, 사용 가능한 Tool의 명세, 행동 지침을 포함하는 시스템 프롬프트
- **동작 흐름:**
    1.  사용자가 자연어로 질문 (e.g., "Langchain 공식 문서에서 Agent에 대한 핵심 내용을 요약해줘")
    2.  에이전트는 질문을 분석하여 웹 정보가 필요하다고 판단 (Reasoning)
    3.  가장 적합한 Tool (`FirecrawlScrapeTool`)과 필요한 인자 (`url`)를 결정 (Reasoning)
    4.  선택한 Tool을 실행 (Action)
    5.  Tool로부터 반환된 웹페이지 본문 텍스트를 확인
    6.  추출된 정보를 바탕으로 사용자의 질문에 대한 최종 답변을 생성하여 제공

#### 4.4. 활용 사례: 무신사 RAG 구현
- **목표:** "무신사 스탠다드 반팔 티셔츠 중 가장 인기있는 상품 3개 알려줘" 와 같은 질문에 답변
- **프로세스:**
    1.  **정보 수집 (Crawl):**
        - 에이전트가 질문을 분석하여 '무신사 스탠다드 반팔 티셔츠' 카테고리 URL이 필요함을 인지. (필요 시 웹 검색 Tool을 추가하여 URL을 찾을 수 있음)
        - `FirecrawlCrawlTool`을 사용하여 해당 카테고리 페이지 및 연관 상품 페이지 크롤링.
    2.  **색인 (Indexing):**
        - 크롤링된 문서들(`List[Document]`)을 `RecursiveCharacterTextSplitter` 등을 사용해 의미 있는 단위(chunk)로 분할.
        - `OpenAIEmbeddings` 또는 `HuggingFaceEmbeddings`를 사용하여 각 chunk를 벡터로 변환.
        - `FAISS` 또는 `ChromaDB` 같은 In-memory Vector Store에 벡터와 원본 텍스트를 저장.
    3.  **검색 및 답변 생성 (Retrieve & Generate):**
        - 사용자의 질문을 임베딩하여 Vector Store에서 가장 유사도가 높은 chunk(상품 정보)들을 검색.
        - 검색된 chunk(Context)와 원본 질문을 함께 LLM에 전달.
        - LLM은 제공된 컨텍스트를 바탕으로 "무신사 스탠다드 반팔 티셔츠 중 인기 상품 3가지는 A, B, C이며 각 상품의 특징은..." 과 같이 자연스러운 답변을 생성.

### 5. 기술 스택 (Tech Stack)
- **언어:** Python 3.10+
- **핵심 라이브러리:**
    - `langchain`, `langchain-openai`
    - `openai`
- **API:**
    - Firecrawl API
    - OpenAI API

### 6. 기대 결과물 (Expected Deliverables)
1.  Firecrawl `scrape`, `crawl` 기능 검증을 위한 Python 스크립트 또는 Jupyter Notebook
2.  `firecrawl_tools.py`: `FirecrawlScrapeTool`과 `FirecrawlCrawlTool` 클래스가 구현된 Python 모듈
3.  `agent_test.py`: Firecrawl Tool을 장착한 Langchain 에이전트의 동작을 시연하는 스크립트
5.  결과 보고서 (README.md): 프로젝트 목표, 과정, 결과 및 시사점을 요약한 문서